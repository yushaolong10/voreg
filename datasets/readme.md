### 1.增强样本集合

```
训练样本
ok1.txt     正样本
not1.csv    负样本  (未结尾)
not2.csv    负样本  (句号但未结尾，对not2_s.csv进行筛选)
not3.csv    负样本  (生成3000样本)

测试样本(注意不包含生成样本)
test_not1.csv 
test_not2.csv
test_ok.csv






cat ok1.csv not3.csv not2.csv not1.csv > train.csv
cat test_not1.csv test_not2.csv test_ok.csv > test.csv

cat datasets/train.csv| sed 's/"//g' > datasets/train1.csv
cat datasets/test.csv| sed 's/"//g' > datasets/test1.csv

```

### 2.训练结果(30轮):
```
python train/train.py
训练数量: 训练集： 19800 验证集： 2200
正样本: 9008, 负样本: 10792, pos_weight: 1.20
epoch= 0 loss=0.3767 lr=9.97e-04 F1=0.8648 P=0.8500 R=0.8800 FPR=0.1275
epoch= 1 loss=0.3284 lr=9.89e-04 F1=0.8656 P=0.8517 R=0.8800 FPR=0.1258
epoch= 2 loss=0.3025 lr=9.76e-04 F1=0.8603 P=0.8638 R=0.8569 FPR=0.1109
epoch= 3 loss=0.2712 lr=9.57e-04 F1=0.8482 P=0.8601 R=0.8367 FPR=0.1118
epoch= 4 loss=0.2367 lr=9.33e-04 F1=0.8610 P=0.8602 R=0.8619 FPR=0.1151
epoch= 5 loss=0.2082 lr=9.05e-04 F1=0.8436 P=0.8527 R=0.8347 FPR=0.1184
epoch= 6 loss=0.1798 lr=8.72e-04 F1=0.8512 P=0.8407 R=0.8619 FPR=0.1341
epoch= 7 loss=0.1571 lr=8.35e-04 F1=0.8361 P=0.8500 R=0.8226 FPR=0.1192
epoch= 8 loss=0.1276 lr=7.94e-04 F1=0.8457 P=0.8487 R=0.8427 FPR=0.1233
epoch= 9 loss=0.1147 lr=7.50e-04 F1=0.8316 P=0.8473 R=0.8165 FPR=0.1209
epoch=10 loss=0.0965 lr=7.04e-04 F1=0.8275 P=0.8485 R=0.8075 FPR=0.1184
epoch=11 loss=0.0848 lr=6.55e-04 F1=0.8382 P=0.8490 R=0.8276 FPR=0.1209
epoch=12 loss=0.0806 lr=6.04e-04 F1=0.8330 P=0.8523 R=0.8145 FPR=0.1159
epoch=13 loss=0.0656 lr=5.53e-04 F1=0.8428 P=0.8480 R=0.8377 FPR=0.1233
epoch=14 loss=0.0610 lr=5.01e-04 F1=0.8348 P=0.8318 R=0.8377 FPR=0.1391
epoch=15 loss=0.0517 lr=4.48e-04 F1=0.8285 P=0.8441 R=0.8135 FPR=0.1233
epoch=16 loss=0.0490 lr=3.97e-04 F1=0.8277 P=0.8478 R=0.8085 FPR=0.1192
epoch=17 loss=0.0423 lr=3.46e-04 F1=0.8265 P=0.8421 R=0.8115 FPR=0.1250
epoch=18 loss=0.0399 lr=2.97e-04 F1=0.8326 P=0.8514 R=0.8145 FPR=0.1167
epoch=19 loss=0.0383 lr=2.51e-04 F1=0.8308 P=0.8478 R=0.8145 FPR=0.1200
epoch=20 loss=0.0357 lr=2.07e-04 F1=0.8332 P=0.8540 R=0.8135 FPR=0.1142
epoch=21 loss=0.0323 lr=1.66e-04 F1=0.8359 P=0.8562 R=0.8165 FPR=0.1126
epoch=22 loss=0.0306 lr=1.29e-04 F1=0.8378 P=0.8451 R=0.8306 FPR=0.1250
epoch=23 loss=0.0297 lr=9.64e-05 F1=0.8350 P=0.8520 R=0.8185 FPR=0.1167
epoch=24 loss=0.0288 lr=6.79e-05 F1=0.8376 P=0.8489 R=0.8266 FPR=0.1209
epoch=25 loss=0.0265 lr=4.42e-05 F1=0.8359 P=0.8562 R=0.8165 FPR=0.1126
epoch=26 loss=0.0259 lr=2.54e-05 F1=0.8335 P=0.8556 R=0.8125 FPR=0.1126
epoch=27 loss=0.0266 lr=1.19e-05 F1=0.8363 P=0.8571 R=0.8165 FPR=0.1118
epoch=28 loss=0.0250 lr=3.74e-06 F1=0.8369 P=0.8549 R=0.8196 FPR=0.1142
epoch=29 loss=0.0250 lr=1.00e-06 F1=0.8369 P=0.8549 R=0.8196 FPR=0.1142

训练完成! 最佳验证集结果: F1=0.8369
test: {'precision': 0.7186978297155937, 'recall': 0.860999999999139, 'fpr': 0.33733733733699967, 'f1': 0.7834394899492043}
```


```
python test.py
==================================================
测试 /v1/text/eou (句末检测)

测试结果:

测试用例数量: 216
正样本数量: 158, 正样本正确数量: 135, 正样本正确率: 85.44%
负样本数量: 58, 负样本正确数量: 40, 负样本正确率: 68.97%
失败用例数量: 41
失败用例比例: 18.98%
```


### 3.训练结果(50轮):
```
python train/train.py
训练数量: 训练集： 19800 验证集： 2200
正样本: 9008, 负样本: 10792, pos_weight: 1.20
epoch= 0 loss=0.3773 lr=9.99e-04 F1=0.8609 P=0.8609 R=0.8609 FPR=0.1142
epoch= 1 loss=0.3322 lr=9.96e-04 F1=0.8650 P=0.8611 R=0.8690 FPR=0.1151
epoch= 2 loss=0.3045 lr=9.91e-04 F1=0.8619 P=0.8619 R=0.8619 FPR=0.1134
epoch= 3 loss=0.2749 lr=9.84e-04 F1=0.8620 P=0.8552 R=0.8690 FPR=0.1209
epoch= 4 loss=0.2437 lr=9.76e-04 F1=0.8563 P=0.8478 R=0.8649 FPR=0.1275
epoch= 5 loss=0.2132 lr=9.65e-04 F1=0.8543 P=0.8577 R=0.8508 FPR=0.1159
epoch= 6 loss=0.1862 lr=9.52e-04 F1=0.8440 P=0.8402 R=0.8478 FPR=0.1325
epoch= 7 loss=0.1616 lr=9.38e-04 F1=0.8467 P=0.8338 R=0.8599 FPR=0.1407
epoch= 8 loss=0.1420 lr=9.22e-04 F1=0.8147 P=0.8349 R=0.7954 FPR=0.1291
epoch= 9 loss=0.1260 lr=9.05e-04 F1=0.8347 P=0.8450 R=0.8246 FPR=0.1242
epoch=10 loss=0.1102 lr=8.85e-04 F1=0.8308 P=0.8402 R=0.8216 FPR=0.1283
epoch=11 loss=0.1073 lr=8.65e-04 F1=0.8219 P=0.8252 R=0.8185 FPR=0.1424
epoch=12 loss=0.0906 lr=8.42e-04 F1=0.8232 P=0.8373 R=0.8095 FPR=0.1291
epoch=13 loss=0.0848 lr=8.19e-04 F1=0.8365 P=0.8455 R=0.8276 FPR=0.1242
epoch=14 loss=0.0822 lr=7.94e-04 F1=0.8402 P=0.8458 R=0.8347 FPR=0.1250
epoch=15 loss=0.0719 lr=7.68e-04 F1=0.8237 P=0.8483 R=0.8004 FPR=0.1175
epoch=16 loss=0.0633 lr=7.41e-04 F1=0.8223 P=0.8282 R=0.8165 FPR=0.1391
epoch=17 loss=0.0606 lr=7.13e-04 F1=0.8257 P=0.8299 R=0.8216 FPR=0.1382
epoch=18 loss=0.0596 lr=6.84e-04 F1=0.8244 P=0.8303 R=0.8185 FPR=0.1374
epoch=19 loss=0.0541 lr=6.55e-04 F1=0.8278 P=0.8394 R=0.8165 FPR=0.1283
epoch=20 loss=0.0528 lr=6.25e-04 F1=0.8234 P=0.8389 R=0.8085 FPR=0.1275
epoch=21 loss=0.0515 lr=5.94e-04 F1=0.8285 P=0.8366 R=0.8206 FPR=0.1316
epoch=22 loss=0.0485 lr=5.63e-04 F1=0.8300 P=0.8515 R=0.8095 FPR=0.1159
epoch=23 loss=0.0459 lr=5.32e-04 F1=0.8229 P=0.8411 R=0.8054 FPR=0.1250
epoch=24 loss=0.0425 lr=5.00e-04 F1=0.8247 P=0.8363 R=0.8135 FPR=0.1308
epoch=25 loss=0.0417 lr=4.69e-04 F1=0.8258 P=0.8449 R=0.8075 FPR=0.1217
epoch=26 loss=0.0391 lr=4.38e-04 F1=0.8295 P=0.8620 R=0.7994 FPR=0.1051
epoch=27 loss=0.0386 lr=4.07e-04 F1=0.8333 P=0.8454 R=0.8216 FPR=0.1233
epoch=28 loss=0.0363 lr=3.76e-04 F1=0.8310 P=0.8471 R=0.8155 FPR=0.1209
epoch=29 loss=0.0319 lr=3.46e-04 F1=0.8402 P=0.8458 R=0.8347 FPR=0.1250
epoch=30 loss=0.0340 lr=3.17e-04 F1=0.8269 P=0.8484 R=0.8065 FPR=0.1184
epoch=31 loss=0.0313 lr=2.88e-04 F1=0.8274 P=0.8385 R=0.8165 FPR=0.1291
epoch=32 loss=0.0301 lr=2.60e-04 F1=0.8298 P=0.8415 R=0.8185 FPR=0.1267
epoch=33 loss=0.0280 lr=2.33e-04 F1=0.8260 P=0.8442 R=0.8085 FPR=0.1225
epoch=34 loss=0.0272 lr=2.07e-04 F1=0.8290 P=0.8450 R=0.8135 FPR=0.1225
epoch=35 loss=0.0282 lr=1.82e-04 F1=0.8306 P=0.8409 R=0.8206 FPR=0.1275
epoch=36 loss=0.0266 lr=1.59e-04 F1=0.8281 P=0.8433 R=0.8135 FPR=0.1242
epoch=37 loss=0.0259 lr=1.36e-04 F1=0.8242 P=0.8461 R=0.8034 FPR=0.1200
epoch=38 loss=0.0261 lr=1.16e-04 F1=0.8241 P=0.8492 R=0.8004 FPR=0.1167
epoch=39 loss=0.0247 lr=9.64e-05 F1=0.8296 P=0.8452 R=0.8145 FPR=0.1225
epoch=40 loss=0.0244 lr=7.88e-05 F1=0.8273 P=0.8493 R=0.8065 FPR=0.1175
epoch=41 loss=0.0242 lr=6.28e-05 F1=0.8287 P=0.8488 R=0.8095 FPR=0.1184
epoch=42 loss=0.0238 lr=4.85e-05 F1=0.8294 P=0.8459 R=0.8135 FPR=0.1217
epoch=43 loss=0.0231 lr=3.61e-05 F1=0.8298 P=0.8468 R=0.8135 FPR=0.1209
epoch=44 loss=0.0228 lr=2.54e-05 F1=0.8275 P=0.8485 R=0.8075 FPR=0.1184
epoch=45 loss=0.0232 lr=1.67e-05 F1=0.8254 P=0.8464 R=0.8054 FPR=0.1200
epoch=46 loss=0.0224 lr=9.85e-06 F1=0.8254 P=0.8464 R=0.8054 FPR=0.1200
epoch=47 loss=0.0220 lr=4.94e-06 F1=0.8254 P=0.8464 R=0.8054 FPR=0.1200
epoch=48 loss=0.0222 lr=1.99e-06 F1=0.8254 P=0.8464 R=0.8054 FPR=0.1200
epoch=49 loss=0.0224 lr=1.00e-06 F1=0.8254 P=0.8464 R=0.8054 FPR=0.1200

训练完成! 最佳验证集结果: F1=0.8254
test: {'precision': 0.7376644736836039, 'recall': 0.896999999999103, 'fpr': 0.3193193193189997, 'f1': 0.8095667865076299}
```


```
python test.py
==================================================
测试 /v1/text/eou (句末检测)

测试结果:

测试用例数量: 216
正样本数量: 158, 正样本正确数量: 149, 正样本正确率: 94.30%
负样本数量: 58, 负样本正确数量: 37, 负样本正确率: 63.79%
失败用例数量: 30
失败用例比例: 13.89%
```